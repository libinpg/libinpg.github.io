# FCN感受野
CNN的强大之处在于它的多层结构能自动学习特征，并且可以学习到多个层次的特征：
较浅的卷积层感知域较小，学习到一些局部区域的特征；较深的卷积层具有较大的感知域，能够学习到更加抽象一些的特征。
这些抽象特征对物体的大小、位置和方向等敏感性更低，从而有助于识别性能的提高。
这些抽象的特征对分类很有帮助，可以很好地判断出一幅图像中包含什么类别的物体，但是因为丢失了一些物体的细节(FCN深层具有较大的感受野，不是每一层都有大的感受野，且这个感受野是有限的，FCN具有感受野，STER论文中也有提到)，不能很好地给出物体的具体轮廓、指出每个像素具体属于哪个物体，因此做到精确的分割就很有难度。

传统的基于CNN的分割方法：为了对一个像素分类，使用该像素周围的一个图像块作为CNN的输入用于训练和预测。这种方法有几个缺点：
一是存储开销很大。
例如对每个像素使用的图像块的大小为15x15，然后不断滑动窗口，每次滑动的窗口给CNN进行判别分类，因此则所需的存储空间根据滑动窗口的次数和大小急剧上升。
二是计算效率低下。相邻的像素块基本上是重复的，针对每个像素块逐个计算卷积，这种计算也有很大程度上的重复。
三是像素块大小的限制了感知区域的大小。通常像素块的大小比整幅图像的大小小很多，只能提取一些局部的特征，从而导致分类的性能受到限制。
而全卷积网络(FCN)则是从抽象的特征中恢复出每个像素所属的类别。即从图像级别的分类进一步延伸到像素级别的分类。

SETR:
  为了与我们的新模型设计形成对比，让我们首先 回顾用于图像语义分割的传统FCN [36]。FCN编码器 由一堆顺序连接的卷积层组成。第一层将图像作为 输入，记为H × W × 3 with H × W 指定以像素为单 位的图像大小。后续层i的输入是一个三维张量大小 为h × w × d，其中h和w是特征图的空间维度，d是特 征/通 道 维 度 。 根 据 张 量 通 过 逐 层 卷 积 连 接 到 的 所 有 较低层的张量的位置计算较高层中的张量的位置， 这些张量被定义为它们的感受野。由于卷积操作的 局部性，感受野沿层的深度线性增加，取决于内核大 小(通常为3 × 3)。因此，只有具有大感受野的较高层才 能对长程依赖性进行建模在这个FCN架构中。然而， 它显示了添加更多层的好处一旦到达一定深度就会 迅速减少 [20]。因此，上下文建模的感受野有限是普 通FCN架构的内在限制。

